<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>论文研读：《Human Mesh Recovery from Monocular Images via a Skeleton-disentangled Representation》 | 滚圆的小橘子的博客</title><meta name="author" content="滚圆的小橘子"><meta name="copyright" content="滚圆的小橘子"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="词汇表                               英中human mesh recovery人体网格恢复monocular image单目图像skeleton-disentangling骨架分解spatial空间的temporal时间的granularity颗粒度decouple解耦disentangling the skeleton from the details(DSD)">
<meta property="og:type" content="article">
<meta property="og:title" content="论文研读：《Human Mesh Recovery from Monocular Images via a Skeleton-disentangled Representation》">
<meta property="og:url" content="http://roundedorange.top/6b1eb231.html">
<meta property="og:site_name" content="滚圆的小橘子的博客">
<meta property="og:description" content="词汇表                               英中human mesh recovery人体网格恢复monocular image单目图像skeleton-disentangling骨架分解spatial空间的temporal时间的granularity颗粒度decouple解耦disentangling the skeleton from the details(DSD)">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://fastly.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg">
<meta property="article:published_time" content="2022-03-08T00:00:00.000Z">
<meta property="article:modified_time" content="2023-04-06T15:19:37.295Z">
<meta property="article:author" content="滚圆的小橘子">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://fastly.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg"><link rel="shortcut icon" href="/pictures/favicon.png"><link rel="canonical" href="http://roundedorange.top/6b1eb231"><link rel="preconnect" href="//fastly.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://fastly.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://fastly.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: undefined,
  noticeOutdate: {"limitDay":200,"position":"top","messagePrev":"离本文章最近更新已有","messageNext":"天，文章内容可能已过时。"},
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":200},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: true,
    post: true
  },
  runtime: '天',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: {"limitCount":50,"languages":{"author":"作者: 滚圆的小橘子","link":"链接: ","source":"来源: 滚圆的小橘子的博客","info":"著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。"}},
  lightbox: 'fancybox',
  Snackbar: {"chs_to_cht":"你已切换为繁体","cht_to_chs":"你已切换为简体","day_to_night":"你已切换为深色模式","night_to_day":"你已切换为浅色模式","bgLight":"#49b1f5","bgDark":"#121212","position":"bottom-left"},
  source: {
    jQuery: 'https://fastly.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js',
    justifiedGallery: {
      js: 'https://fastly.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
      css: 'https://fastly.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
    },
    fancybox: {
      js: 'https://fastly.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js',
      css: 'https://fastly.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css'
    }
  },
  isPhotoFigcaption: true,
  islazyload: false,
  isanchor: true
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '论文研读：《Human Mesh Recovery from Monocular Images via a Skeleton-disentangled Representation》',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2023-04-06 15:19:37'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const fontSizeVal = saveToLocal.get('global-font-size')
    if (fontSizeVal !== undefined) {
      document.documentElement.style.setProperty('--global-font-size', fontSizeVal + 'px')
    }
    
    const detectApple = () => {
      if (GLOBAL_CONFIG_SITE.isHome && /iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><link rel="stylesheet" href="/css/background.css"><link rel="stylesheet" href="/css/copyright.css"><link rel="stylesheet" href="/css/custom/twikoo_beautify.css"  media="defer" onload="this.media='all'"><!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiper.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiperstyle.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-tag-plugins-plus@latest/lib/assets/font-awesome-animation.min.css" media="defer" onload="this.media='all'"><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-tag-plugins-plus@latest/lib/tag_plugins.css" media="defer" onload="this.media='all'"><script src="https://npm.elemecdn.com/hexo-butterfly-tag-plugins-plus@latest/lib/assets/carousel-touch.js"></script><!-- hexo injector head_end end --><meta name="generator" content="Hexo 5.4.2"></head><body><div id="loading-box"><div class="loading-left-bg"></div><div class="loading-right-bg"></div><div class="spinner-box"><div class="configure-border-1"><div class="configure-core"></div></div><div class="configure-border-2"><div class="configure-core"></div></div><div class="loading-word">加载中...</div></div></div><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/pictures/avatar.jpg" onerror="onerror=null;src='/pictures/friend_404.gif'" alt="avatar"/></div><div class="site-data"><div class="data-item is-center"><div class="data-item-link"><a href="/archives/"><div class="headline">文章</div><div class="length-num">32</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/categories/"><div class="headline">分类</div><div class="length-num">8</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/kagamine/"><i class="fa-fw fas fa-heart"></i><span> 镜音的小窝</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/comments/"><i class="fa-fw fas fa-comment"></i><span> 留言板</span></a></div><div class="menus_item"><a class="site-page" href="/4806bed7.html"><i class="fa-fw fas fa-user-circle"></i><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://fastly.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg')"><nav id="nav"><span id="blog_name"><a id="site-name" onclick="btf.scrollToDest(0, 500)" data-title="嘿咻~">论文研读：《Human Mesh Recovery from Monocular Images via a Skeleton-disentangled Representation》</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/kagamine/"><i class="fa-fw fas fa-heart"></i><span> 镜音的小窝</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/comments/"><i class="fa-fw fas fa-comment"></i><span> 留言板</span></a></div><div class="menus_item"><a class="site-page" href="/4806bed7.html"><i class="fa-fw fas fa-user-circle"></i><span> 关于</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">论文研读：《Human Mesh Recovery from Monocular Images via a Skeleton-disentangled Representation》</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2022-03-08T00:00:00.000Z" title="发表于 2022-03-08 00:00:00">2022-03-08</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2023-04-06T15:19:37.295Z" title="更新于 2023-04-06 15:19:37">2023-04-06</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/HMR/">HMR</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">2.4k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>7分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="论文研读：《Human Mesh Recovery from Monocular Images via a Skeleton-disentangled Representation》"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><details class="folding-tag" blue><summary> 词汇表 </summary>
              <div class='content'>
              <div class="table-container"><table><thead><tr><th style="text-align:center">英</th><th style="text-align:center">中</th></tr></thead><tbody><tr><td style="text-align:center">human mesh recovery</td><td style="text-align:center">人体网格恢复</td></tr><tr><td style="text-align:center">monocular image</td><td style="text-align:center">单目图像</td></tr><tr><td style="text-align:center">skeleton-disentangling</td><td style="text-align:center">骨架分解</td></tr><tr><td style="text-align:center">spatial</td><td style="text-align:center">空间的</td></tr><tr><td style="text-align:center">temporal</td><td style="text-align:center">时间的</td></tr><tr><td style="text-align:center">granularity</td><td style="text-align:center">颗粒度</td></tr><tr><td style="text-align:center">decouple</td><td style="text-align:center">解耦</td></tr><tr><td style="text-align:center">disentangling the skeleton from the details(DSD)</td><td style="text-align:center">从细节中分离骨架</td></tr><tr><td style="text-align:center">self-attention</td><td style="text-align:center">自注意力</td></tr><tr><td style="text-align:center">convolution</td><td style="text-align:center">卷积</td></tr><tr><td style="text-align:center">adversarial</td><td style="text-align:center">对抗的</td></tr><tr><td style="text-align:center">ablation study</td><td style="text-align:center">消融研究</td></tr><tr><td style="text-align:center">statistical human body model(SMPL)</td><td style="text-align:center">统计人体模型</td></tr></tbody></table></div>
              </div>
            </details>
<h1 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h1><ul>
<li>目前大多数方法通过从一个耦合特性中得到复杂的3D姿势、体型和镜头参数来进行人体网格恢复</li>
<li>作者提供一个基于骨架分离的框架，以解耦的方式将HMR的任务分成多维度的空间的与时间的颗粒度</li>
<li>在空间维度，作者提供了可插拔的模块DSD（从细节中分离骨架）。DSD能降低复杂度，并对骨架进行解耦，所以为时间建模提供良好基础。</li>
<li>在时间维度，作者提出基于自监督的时域卷积网络，用它来挖掘短期和长期的时间线索。</li>
<li>此外，作者用无监督对抗训练，通过打乱时间片然后恢复顺序的方法，来提升对运动动力学的学习能力。</li>
<li>消融学习证明了在时间建模和归一化领域中，骨架分离的表示方法更加重要了。</li>
</ul>
<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><h2 id="先前的HMR方法"><a href="#先前的HMR方法" class="headerlink" title="先前的HMR方法"></a>先前的HMR方法</h2><ul>
<li>传统3D姿势通常通过预测14/17骨架关节的位置来实现的</li>
<li>从单目图片进行3D的HMR较复杂，预测3D体型和关节角度的更多细节。要预测多于85个参数，这些参数控制着6890个构成3D网格表面的节点。3D场景映射到2D图像的信息损失、自身模糊程度、人的体格与姿势变换让这项工作更难完成</li>
<li>在从单张图片中恢复人体3D网格时，原先的多阶段解法是，首先提取人体信息（如2D姿势和分割），然后从中预测3D模型参数。</li>
<li>HMR用端到端的解法学习映射，该映射直接从图片像素映射到模型参数。这比两阶段解法表现更好，但因为耦合问题，这种猜测方法不稳定。</li>
<li>HMR中，用全连接层（fully connected layer）就能从同一些特征向量中得到3D姿势、体型和相机参数。</li>
</ul>
<h2 id="耦合问题的产生原因"><a href="#耦合问题的产生原因" class="headerlink" title="耦合问题的产生原因"></a>耦合问题的产生原因</h2><ul>
<li>由于①不解耦的话，不同目标的特征耦合度就很高②目前有3D注释的数据集都是在限制条件很多的环境中采集的。所以很多前人为了让模型学习更丰富的姿势，采用2D野外姿势数据集。这在3D姿势预测中有用，但在3D网格恢复中，2D姿势远远不够用于恢复复杂的3D姿势和体型。</li>
<li>缺乏监督导致预测的细节很脆弱，因此耦合问题更严重了。因为耦合问题严重，所以训练出来的模型不能很好地用于复杂环境和多样的人体姿势。</li>
</ul>
<h2 id="DSD模型简述"><a href="#DSD模型简述" class="headerlink" title="DSD模型简述"></a>DSD模型简述</h2><ul>
<li>为了解决耦合问题，作者使用一个轻量级、可插拔的DSD模型，通过端到端的方法解耦不同参数。</li>
<li>DSD模型的主思路为：用双线性变换从3D网格的细节中分离骨架。</li>
<li>DSD工作流程<ol>
<li>各自独立地抽取出姿势骨架的信息和其他细节（如体型和详细姿势信息）</li>
<li>用双线性变换统计上述两部分信息，同时在新的特征空间中保持他们的解耦性。</li>
<li>训练端到端的网络来保存全局最优解。</li>
</ol>
</li>
<li>DSD模块能很容易插入其他2D/3D预测网络来恢复3D人体骨架。</li>
</ul>
<h2 id="SATN模型简述"><a href="#SATN模型简述" class="headerlink" title="SATN模型简述"></a>SATN模型简述</h2><ul>
<li>不同的3D姿势可能对应同一张2D图，因此从单张图片进行3D的HMR有模糊性。作者引入了自监督时间网络（SATN）对相邻的帧进行预测，从而解决上述问题。</li>
<li>SATN由自监督模块和TCN（时间卷积网络）构成。</li>
<li>采用TCN是因为它能高效并行计算、优秀的短期建模能力。</li>
</ul>
<h3 id="自监督模块的作用"><a href="#自监督模块的作用" class="headerlink" title="自监督模块的作用"></a>自监督模块的作用</h3><ul>
<li>卷积层的层次结构限制了长期序列的学习。如果两帧的距离大于单个卷积层的核大小，则该模型要求提供一个卷积层的栈来建立长期联系，从而将这两帧联系起来。这很不高效。</li>
<li>想法：要是有一个一开始就能建立联系的网络就好了。所以在TCN前我们要用自监督来联系时间上的特征。只要用一个自监督层就能建立起所有帧之间有价值的联系。</li>
<li>通过这种方式，在时间网络的底层就能建立起联系，大大有助于TCN学习短期和长期的时间一致性。</li>
</ul>
<h3 id="无监督对抗训练"><a href="#无监督对抗训练" class="headerlink" title="无监督对抗训练"></a>无监督对抗训练</h3><ul>
<li>对于视频中的一帧t，SATN预测帧t的3D人体骨架，监督也只监督帧t。我们不知道SATN有没有学到长期的关系。即：缺乏学习长期联系的监督。</li>
<li>所以采用无监督对抗训练，通过视频帧的顺序来学习时间关系。</li>
<li>无监督对抗训练的流程<ol>
<li>视频帧被打乱顺序，然后用自监督和排序序列模块来重新排序。</li>
<li>在恢复正确的时间顺序过程中，一个能用来学习运动动力学的超强监督信号诞生了。</li>
</ol>
</li>
</ul>
<h2 id="贡献总结"><a href="#贡献总结" class="headerlink" title="贡献总结"></a>贡献总结</h2><ul>
<li>高效的、可移植的DSD模块用来分离人体3D网格的剩余部分。它降低复杂度，为往后时间建模打下良好基础。</li>
<li>自监督时间网络用来学习短期和长期3D人体的时间一致性。</li>
<li>无监督对抗学习用来引导模型学习视频的运动动力学</li>
<li>整个框架都是用端到端的方法训练的。</li>
</ul>
<h1 id="Related-Work"><a href="#Related-Work" class="headerlink" title="Related Work"></a>Related Work</h1><h2 id="Recovering-3D-Human-mesh-from-single-images"><a href="#Recovering-3D-Human-mesh-from-single-images" class="headerlink" title="Recovering 3D Human mesh from single images"></a>Recovering 3D Human mesh from single images</h2><ul>
<li>最近，在从单张图片恢复3D人体网格问题中，基于卷积网络的方法表现突出。可分为两类：二阶段法、直接预测法。<ol>
<li>二阶段法<ol>
<li>流程<ol>
<li>首先预测中间结果（如人体解析）</li>
<li>从中预测SMPL参数</li>
</ol>
</li>
<li>二阶段法在域转换中很给力，但扔掉了人体重要信息。</li>
</ol>
</li>
<li>直接预测法</li>
</ol>
</li>
</ul>
<h2 id="Recovering-3D-pose-from-monocular-video"><a href="#Recovering-3D-pose-from-monocular-video" class="headerlink" title="Recovering 3D pose from monocular video"></a>Recovering 3D pose from monocular video</h2><ul>
<li>目前处理这类问题的方法可分为两类：<ol>
<li>基于最优化的方法</li>
<li>基于卷积神经网络（CNN）的方法</li>
</ol>
</li>
<li>基于CNN的方法效率较低。</li>
<li>HMR中用TCN通过预测当前帧的前后动作来学习运动动力学。</li>
</ul>
<h1 id="Method"><a href="#Method" class="headerlink" title="Method"></a>Method</h1><ul>
<li>对于单张图片，直接用Resnet-50提取特征，并从特征中预测Θ。作者在最后的完全连通层之前插入DSD模块，因为DSD模块既能重新整理耦合问题、还能从特征空间中剩下的细节中分离骨架。</li>
<li>对于单目视频，用DSD模块对一些特征重新整理，然后用SATN预测Θ。</li>
<li>SATN包括了自监督模块和TCN。</li>
<li>用对抗训练帮助自监督模块学习视频中的运动动力学。</li>
<li>正确的时间顺序的特征送入TCN来预测人体3D骨架<script type="math/tex">Θ_t</script>。</li>
</ul>
<h2 id="3D-Human-Body-Representation"><a href="#3D-Human-Body-Representation" class="headerlink" title="3D Human Body Representation"></a>3D Human Body Representation</h2><ul>
<li>SMPL是一个参数统计3D人体模型，用来将3D网格加密成低维参数。</li>
<li>为了用2D姿势标签监督eD网格，我们用一个弱透视相机模型建立3D空间到2D平面的映射。</li>
<li>最终一个85维的向量<script type="math/tex">Θ= \{ \theta,\beta,R,t,s \}</script>用来表示相机视角下的3D人体。</li>
</ul>
<h2 id="DSD模块"><a href="#DSD模块" class="headerlink" title="DSD模块"></a>DSD模块</h2><ul>
<li>首先要从每一帧中提取3D网格信息。</li>
<li>DSD的两个好处：<ol>
<li>解耦能进行稀释的任务分割，从而降低复杂度</li>
<li>分离骨架的表示方法更有利于探索时间上的运动动力学。</li>
</ol>
</li>
<li>用两个分支的结构分别提取骨架特征和其他特征。</li>
<li>各自提取完特征后，要找个方法整合他们。用二线性变换来从其他细节中分离骨架。</li>
<li>DSD模块可移植到其他网络。</li>
</ul>
<h2 id="Self-attention-Temporal-Network"><a href="#Self-attention-Temporal-Network" class="headerlink" title="Self-attention Temporal Network"></a>Self-attention Temporal Network</h2><ul>
<li>自监督时间网络（SATN）用来学习短期和长期的时间一致性。</li>
<li>从DSD模块拿到骨架分离特征后，SATN预测更加平滑的Θ。</li>
<li>TCN对短期建模很好，但因为它的层次结构，所以长期关系建模不好。所以我们把TCN建立在自监督模块之上。</li>
<li>多头监督（MHA）被用于完成自监督</li>
<li>虽然我们预测了时间上的多帧特征，监督还是在单帧的水平。缺乏对长期预测的监督。所以作者采用无监督对抗训练。</li>
</ul>
<h2 id="Loss-Functions"><a href="#Loss-Functions" class="headerlink" title="Loss Functions"></a>Loss Functions</h2><h1 id="Experiments"><a href="#Experiments" class="headerlink" title="Experiments"></a>Experiments</h1><h2 id="Datasets"><a href="#Datasets" class="headerlink" title="Datasets"></a>Datasets</h2><ul>
<li>只采用了Human3.6M数据集，这数据集是有3D注释的。</li>
</ul>
<h2 id="Implement-Details"><a href="#Implement-Details" class="headerlink" title="Implement Details"></a>Implement Details</h2><ul>
<li>框架有时间和空间部分。空间部分：从ResNet-50中提取特征，在MPII上与训练，然后用DSD模块解耦。时间部分：收集视频特征送到SATN。</li>
</ul>
<h2 id="Evaluation-of-the-DSD-module"><a href="#Evaluation-of-the-DSD-module" class="headerlink" title="Evaluation of the DSD module"></a>Evaluation of the DSD module</h2><ul>
<li>DSD使3D姿势恢复更高效</li>
<li>DSD让骨架分离很充分</li>
<li>DSD让预测结果更稳定</li>
</ul>
<h2 id="Evaluation-of-SATN"><a href="#Evaluation-of-SATN" class="headerlink" title="Evaluation of SATN"></a>Evaluation of SATN</h2><ul>
<li>SATN让预测更加顺滑</li>
<li>让TCN越早建立联系越好，自监督模块表现得很好。</li>
</ul>
<h1 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h1><p>没什么东西。。。</p>
</article><div class="post-copyright"><div class="post-copyright__title"><span class="post-copyright-info"><h>论文研读：《Human Mesh Recovery from Monocular Images via a Skeleton-disentangled Representation》</h></span></div><div class="post-copyright__type"><span class="post-copyright-info"><a href="http://roundedorange.top/6b1eb231.html">http://roundedorange.top/6b1eb231.html</a></span></div><div class="post-copyright-m"><div class="post-copyright-m-info"><div class="post-copyright-a" style="display: inline-block;width: 120px"><h>作者</h><div class="post-copyright-cc-info"><h>滚圆的小橘子</h></div></div><div class="post-copyright-c" style="display: inline-block;width: 120px"><h>发布于</h><div class="post-copyright-cc-info"><h>2022-03-08</h></div></div><div class="post-copyright-u" style="display: inline-block;width: 120px"><h>更新于</h><div class="post-copyright-cc-info"><h>2023-04-06</h></div></div><div class="post-copyright-c" style="display: inline-block;width: 120px"><h>许可协议</h><div class="post-copyright-cc-info"><a class="icon" rel="noopener" target="_blank" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a><a rel="noopener" target="_blank" title="CC BY 4.0" href="https://creativecommons.org/licenses/by/4.0/deed.zh">CC BY 4.0</a></div></div></div></div></div><div class="tag_share"><div class="post_share"><div class="social-share" data-image="https://fastly.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://fastly.jsdelivr.net/npm/social-share.js/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://fastly.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js" defer></script></div></div><link rel="stylesheet" href="/css/coin.css" media="defer" onload="this.media='all'"/><div class="post-reward"><button class="tip-button reward-button"><span class="tip-button__text">打赏给小橘子</span><div class="coin-wrapper"><div class="coin"><div class="coin__middle"></div><div class="coin__back"></div><div class="coin__front"></div></div></div><div class="reward-main"><ul class="reward-all"><li class="reward-item"><a href="/pictures/alipay.jpg" target="_blank"><img class="post-qr-code-img" src="/pictures/alipay.jpg" alt="支付宝"/></a><div class="post-qr-code-desc">支付宝</div></li></ul></div></button></div><audio id="coinAudio" src="https://npm.elemecdn.com/akilar-candyassets@1.0.16/audio/coin.mp3"></audio><script defer="defer" src="/js/coin.js"></script><hr/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div id="twikoo-wrap"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Abstract"><span class="toc-number">1.</span> <span class="toc-text">Abstract</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Introduction"><span class="toc-number">2.</span> <span class="toc-text">Introduction</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%85%88%E5%89%8D%E7%9A%84HMR%E6%96%B9%E6%B3%95"><span class="toc-number">2.1.</span> <span class="toc-text">先前的HMR方法</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%80%A6%E5%90%88%E9%97%AE%E9%A2%98%E7%9A%84%E4%BA%A7%E7%94%9F%E5%8E%9F%E5%9B%A0"><span class="toc-number">2.2.</span> <span class="toc-text">耦合问题的产生原因</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#DSD%E6%A8%A1%E5%9E%8B%E7%AE%80%E8%BF%B0"><span class="toc-number">2.3.</span> <span class="toc-text">DSD模型简述</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#SATN%E6%A8%A1%E5%9E%8B%E7%AE%80%E8%BF%B0"><span class="toc-number">2.4.</span> <span class="toc-text">SATN模型简述</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%87%AA%E7%9B%91%E7%9D%A3%E6%A8%A1%E5%9D%97%E7%9A%84%E4%BD%9C%E7%94%A8"><span class="toc-number">2.4.1.</span> <span class="toc-text">自监督模块的作用</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AF%B9%E6%8A%97%E8%AE%AD%E7%BB%83"><span class="toc-number">2.4.2.</span> <span class="toc-text">无监督对抗训练</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%B4%A1%E7%8C%AE%E6%80%BB%E7%BB%93"><span class="toc-number">2.5.</span> <span class="toc-text">贡献总结</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Related-Work"><span class="toc-number">3.</span> <span class="toc-text">Related Work</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Recovering-3D-Human-mesh-from-single-images"><span class="toc-number">3.1.</span> <span class="toc-text">Recovering 3D Human mesh from single images</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Recovering-3D-pose-from-monocular-video"><span class="toc-number">3.2.</span> <span class="toc-text">Recovering 3D pose from monocular video</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Method"><span class="toc-number">4.</span> <span class="toc-text">Method</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#3D-Human-Body-Representation"><span class="toc-number">4.1.</span> <span class="toc-text">3D Human Body Representation</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#DSD%E6%A8%A1%E5%9D%97"><span class="toc-number">4.2.</span> <span class="toc-text">DSD模块</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Self-attention-Temporal-Network"><span class="toc-number">4.3.</span> <span class="toc-text">Self-attention Temporal Network</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Loss-Functions"><span class="toc-number">4.4.</span> <span class="toc-text">Loss Functions</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Experiments"><span class="toc-number">5.</span> <span class="toc-text">Experiments</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Datasets"><span class="toc-number">5.1.</span> <span class="toc-text">Datasets</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Implement-Details"><span class="toc-number">5.2.</span> <span class="toc-text">Implement Details</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Evaluation-of-the-DSD-module"><span class="toc-number">5.3.</span> <span class="toc-text">Evaluation of the DSD module</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Evaluation-of-SATN"><span class="toc-number">5.4.</span> <span class="toc-text">Evaluation of SATN</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Conclusion"><span class="toc-number">6.</span> <span class="toc-text">Conclusion</span></a></li></ol></div></div></div></div></main><footer id="footer" style="background-image: url('https://fastly.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg')"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2023 By 滚圆的小橘子</div><div class="footer_custom_text"><a href="https://icp.gov.moe/?keyword=20228421" target="_blank">萌ICP备20228421号</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="font-plus" type="button" title="放大字体"><i class="fas fa-plus"></i></button><button id="font-minus" type="button" title="缩小字体"><i class="fas fa-minus"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="chat_btn" type="button" title="rightside.chat_btn"><i class="fas fa-sms"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><div class="search-dialog__title" id="local-search-title">本地搜索</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div></div><hr/><div id="local-search-results"></div><span class="search-close-button"><i class="fas fa-times"></i></span></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://fastly.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.js"></script><script src="/js/search/local-search.js"></script><script>var preloader = {
  endLoading: () => {
    document.body.style.overflow = 'auto';
    document.getElementById('loading-box').classList.add("loaded")
  },
  initLoading: () => {
    document.body.style.overflow = '';
    document.getElementById('loading-box').classList.remove("loaded")

  }
}
window.addEventListener('load',preloader.endLoading())</script><div class="js-pjax"><script>(()=>{
  const $countDom = document.getElementById('twikoo-count')
  const init = () => {
    twikoo.init(Object.assign({
      el: '#twikoo-wrap',
      envId: 'environment-8gzfnzxyeedc08e9',
      region: ''
    }, null))
  }

  const getCount = () => {
    twikoo.getCommentsCount({
      envId: 'environment-8gzfnzxyeedc08e9',
      region: '',
      urls: [window.location.pathname],
      includeReply: false
    }).then(function (res) {
      $countDom.innerText = res[0].count
    }).catch(function (err) {
      console.error(err);
    });
  }

  const loadTwikoo = (bool = false) => {
    if (typeof twikoo === 'object') {
      init()
      bool && $countDom && setTimeout(getCount,0)
    } else {
      getScript('https://fastly.jsdelivr.net/npm/twikoo/dist/twikoo.all.min.js').then(()=> {
        init()
        bool && $countDom && setTimeout(getCount,0)
      })
    }
  }

  if ('Twikoo' === 'Twikoo' || !true) {
    if (true) btf.loadComment(document.getElementById('twikoo-wrap'), loadTwikoo)
    else loadTwikoo(true)
  } else {
    window.loadOtherComment = () => {
      loadTwikoo()
    }
  }
})()</script></div><script defer data-pjax src="/js/kernel.js"></script><script defer data-pjax src="/js/tongji.js"></script><canvas class="fireworks" mobile="false"></canvas><script src="https://fastly.jsdelivr.net/npm/butterfly-extsrc@1/dist/fireworks.min.js"></script><script src="//code.tidio.co/nwdy4oqyxwgfsh9wggjjluoe8qtkpdxp.js" async="async"></script><script>function onTidioChatApiReady() {
  window.tidioChatApi.hide();
  window.tidioChatApi.on("close", function() {
    window.tidioChatApi.hide();
  });
}
if (window.tidioChatApi) {
  window.tidioChatApi.on("ready", onTidioChatApiReady);
} else {
  document.addEventListener("tidioChat-ready", onTidioChatApiReady);
}

var chatBtnFn = () => {
  document.getElementById("chat_btn").addEventListener("click", function(){
    window.tidioChatApi.show();
    window.tidioChatApi.open();
  });
}
chatBtnFn()
</script><link rel="stylesheet" href="https://fastly.jsdelivr.net/npm/aplayer/dist/APlayer.min.css" media="print" onload="this.media='all'"><script src="https://fastly.jsdelivr.net/npm/aplayer/dist/APlayer.min.js"></script><script src="https://fastly.jsdelivr.net/gh/metowolf/MetingJS@1.2/dist/Meting.min.js"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><!-- hexo injector body_end start --><script data-pjax>
  function butterfly_swiper_injector_config(){
    var parent_div_git = document.getElementById('recent-posts');
    var item_html = '<div class="recent-post-item" style="height: auto;width: 100%"><div class="blog-slider swiper-container-fade swiper-container-horizontal" id="swiper_container"><div class="blog-slider__wrp swiper-wrapper" style="transition-duration: 0ms;"><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="db37c32a.html" alt=""><img width="48" height="48" src="https://fastly.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2022-03-23</span><a class="blog-slider__title" href="db37c32a.html" alt="">论文研读：《A Lightweight Graph Transformer Network for Human Mesh Reconstruction from 2D Human Pose》</a><div class="blog-slider__text">再怎么看我也不知道怎么描述它的啦！</div><a class="blog-slider__button" href="db37c32a.html" alt="">详情   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="a199460c.html" alt=""><img width="48" height="48" src="https://fastly.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2022-01-12</span><a class="blog-slider__title" href="a199460c.html" alt="">山东大学软件学院线性代数笔记</a><div class="blog-slider__text">再怎么看我也不知道怎么描述它的啦！</div><a class="blog-slider__button" href="a199460c.html" alt="">详情   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="8ae5cf92.html" alt=""><img width="48" height="48" src="https://fastly.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2022-01-09</span><a class="blog-slider__title" href="8ae5cf92.html" alt="">2021山东大学-HarmonyOS移动应用开发学习笔记</a><div class="blog-slider__text">再怎么看我也不知道怎么描述它的啦！</div><a class="blog-slider__button" href="8ae5cf92.html" alt="">详情   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="a1d74d45.html" alt=""><img width="48" height="48" src="https://fastly.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2022-03-07</span><a class="blog-slider__title" href="a1d74d45.html" alt="">TiDB知识速览</a><div class="blog-slider__text">再怎么看我也不知道怎么描述它的啦！</div><a class="blog-slider__button" href="a1d74d45.html" alt="">详情   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="d0daaef9.html" alt=""><img width="48" height="48" src="https://fastly.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2021-12-10</span><a class="blog-slider__title" href="d0daaef9.html" alt="">LaTeX安装教程（TexMaker+MiKTeX）</a><div class="blog-slider__text">再怎么看我也不知道怎么描述它的啦！</div><a class="blog-slider__button" href="d0daaef9.html" alt="">详情   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="3ae63a08.html" alt=""><img width="48" height="48" src="https://fastly.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2021-10-30</span><a class="blog-slider__title" href="3ae63a08.html" alt="">利用TF-IDF进行基于内容的推荐</a><div class="blog-slider__text">再怎么看我也不知道怎么描述它的啦！</div><a class="blog-slider__button" href="3ae63a08.html" alt="">详情   </a></div></div></div><div class="blog-slider__pagination swiper-pagination-clickable swiper-pagination-bullets"></div></div></div>';
    console.log('已挂载butterfly_swiper')
    parent_div_git.insertAdjacentHTML("afterbegin",item_html)
    }
  var elist = 'undefined'.split(',');
  var cpage = location.pathname;
  var epage = 'all';
  var flag = 0;

  for (var i=0;i<elist.length;i++){
    if (cpage.includes(elist[i])){
      flag++;
    }
  }

  if ((epage ==='all')&&(flag == 0)){
    butterfly_swiper_injector_config();
  }
  else if (epage === cpage){
    butterfly_swiper_injector_config();
  }
  </script><script defer src="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiper.min.js"></script><script defer data-pjax src="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiper_init.js"></script><script async src="//at.alicdn.com/t/font_2032782_8d5kxvn09md.js"></script><!-- hexo injector body_end end --></body></html>