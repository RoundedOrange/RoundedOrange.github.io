<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>论文研读：《A Lightweight Graph Transformer Network for Human Mesh Reconstruction from 2D Human Pose》 | 滚圆的小橘子的博客</title><meta name="author" content="滚圆的小橘子"><meta name="copyright" content="滚圆的小橘子"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="词汇表                               英中human pose estimation(HPE)人体姿态估计human body articulation人体关节depth ambiguity深度模糊occlusion遮挡问题end-to-end端到端的off-the-shelf现成的front end前端modular模块化的be incorporated with">
<meta property="og:type" content="article">
<meta property="og:title" content="论文研读：《A Lightweight Graph Transformer Network for Human Mesh Reconstruction from 2D Human Pose》">
<meta property="og:url" content="http://roundedorange.top/db37c32a.html">
<meta property="og:site_name" content="滚圆的小橘子的博客">
<meta property="og:description" content="词汇表                               英中human pose estimation(HPE)人体姿态估计human body articulation人体关节depth ambiguity深度模糊occlusion遮挡问题end-to-end端到端的off-the-shelf现成的front end前端modular模块化的be incorporated with">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg">
<meta property="article:published_time" content="2022-03-23T00:00:00.000Z">
<meta property="article:modified_time" content="2022-05-03T04:39:34.589Z">
<meta property="article:author" content="滚圆的小橘子">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg"><link rel="shortcut icon" href="/pictures/favicon.png"><link rel="canonical" href="http://roundedorange.top/db37c32a"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: undefined,
  noticeOutdate: {"limitDay":200,"position":"top","messagePrev":"离本文章最近更新已有","messageNext":"天，文章内容可能已过时。"},
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":200},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: true,
    post: true
  },
  runtime: '天',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: {"limitCount":50,"languages":{"author":"作者: 滚圆的小橘子","link":"链接: ","source":"来源: 滚圆的小橘子的博客","info":"著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。"}},
  lightbox: 'fancybox',
  Snackbar: {"chs_to_cht":"你已切换为繁体","cht_to_chs":"你已切换为简体","day_to_night":"你已切换为深色模式","night_to_day":"你已切换为浅色模式","bgLight":"#49b1f5","bgDark":"#121212","position":"bottom-left"},
  source: {
    jQuery: 'https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js',
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
    },
    fancybox: {
      js: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js',
      css: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css'
    }
  },
  isPhotoFigcaption: true,
  islazyload: false,
  isanchor: true
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '论文研读：《A Lightweight Graph Transformer Network for Human Mesh Reconstruction from 2D Human Pose》',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2022-05-03 04:39:34'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const fontSizeVal = saveToLocal.get('global-font-size')
    if (fontSizeVal !== undefined) {
      document.documentElement.style.setProperty('--global-font-size', fontSizeVal + 'px')
    }
    
    const detectApple = () => {
      if (GLOBAL_CONFIG_SITE.isHome && /iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><link rel="stylesheet" href="/css/background.css"><link rel="stylesheet" href="/css/copyright.css"><link rel="stylesheet" href="/css/custom/twikoo_beautify.css"  media="defer" onload="this.media='all'"><!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<link rel="stylesheet" href="https://unpkg.zhimg.com/hexo-butterfly-swiper/lib/swiper.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://unpkg.zhimg.com/hexo-butterfly-swiper/lib/swiperstyle.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-filter-gitcalendar/lib/gitcalendar.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-tag-plugins-plus@latest/lib/assets/font-awesome-animation.min.css" media="defer" onload="this.media='all'"><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-tag-plugins-plus@latest/lib/tag_plugins.css" media="defer" onload="this.media='all'"><script src="https://npm.elemecdn.com/hexo-butterfly-tag-plugins-plus@latest/lib/assets/carousel-touch.js"></script><!-- hexo injector head_end end --><meta name="generator" content="Hexo 5.4.0"><style>mjx-container[jax="SVG"] {
  direction: ltr;
}

mjx-container[jax="SVG"] > svg {
  overflow: visible;
}

mjx-container[jax="SVG"][display="true"] {
  display: block;
  text-align: center;
  margin: 1em 0;
}

mjx-container[jax="SVG"][justify="left"] {
  text-align: left;
}

mjx-container[jax="SVG"][justify="right"] {
  text-align: right;
}

g[data-mml-node="merror"] > g {
  fill: red;
  stroke: red;
}

g[data-mml-node="merror"] > rect[data-background] {
  fill: yellow;
  stroke: none;
}

g[data-mml-node="mtable"] > line[data-line] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > rect[data-frame] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > .mjx-dashed {
  stroke-dasharray: 140;
}

g[data-mml-node="mtable"] > .mjx-dotted {
  stroke-linecap: round;
  stroke-dasharray: 0,140;
}

g[data-mml-node="mtable"] > svg {
  overflow: visible;
}

[jax="SVG"] mjx-tool {
  display: inline-block;
  position: relative;
  width: 0;
  height: 0;
}

[jax="SVG"] mjx-tool > mjx-tip {
  position: absolute;
  top: 0;
  left: 0;
}

mjx-tool > mjx-tip {
  display: inline-block;
  padding: .2em;
  border: 1px solid #888;
  font-size: 70%;
  background-color: #F8F8F8;
  color: black;
  box-shadow: 2px 2px 5px #AAAAAA;
}

g[data-mml-node="maction"][data-toggle] {
  cursor: pointer;
}

mjx-status {
  display: block;
  position: fixed;
  left: 1em;
  bottom: 1em;
  min-width: 25%;
  padding: .2em .4em;
  border: 1px solid #888;
  font-size: 90%;
  background-color: #F8F8F8;
  color: black;
}

foreignObject[data-mjx-xml] {
  font-family: initial;
  line-height: normal;
  overflow: visible;
}

.MathJax path {
  stroke-width: 3;
}

mjx-container[display="true"] {
  overflow: auto hidden;
}

mjx-container[display="true"] + br {
  display: none;
}
</style></head><body><div id="loading-box"><div class="loading-left-bg"></div><div class="loading-right-bg"></div><div class="spinner-box"><div class="configure-border-1"><div class="configure-core"></div></div><div class="configure-border-2"><div class="configure-core"></div></div><div class="loading-word">加载中...</div></div></div><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/pictures/avatar.jpg" onerror="onerror=null;src='/pictures/friend_404.gif'" alt="avatar"/></div><div class="site-data"><div class="data-item is-center"><div class="data-item-link"><a href="/archives/"><div class="headline">文章</div><div class="length-num">24</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/categories/"><div class="headline">分类</div><div class="length-num">8</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/kagamine/"><i class="fa-fw fas fa-heart"></i><span> 镜音的小窝</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/artitalk/"><i class="fa-fw fas fa-commenting"></i><span> 说说</span></a></div><div class="menus_item"><a class="site-page" href="/comments/"><i class="fa-fw fas fa-comment"></i><span> 留言板</span></a></div><div class="menus_item"><a class="site-page" href="/4806bed7.html"><i class="fa-fw fas fa-user-circle"></i><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg')"><nav id="nav"><span id="blog_name"><a id="site-name" onclick="btf.scrollToDest(0, 500)" data-title="嘿咻~">论文研读：《A Lightweight Graph Transformer Network for Human Mesh Reconstruction from 2D Human Pose》</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/kagamine/"><i class="fa-fw fas fa-heart"></i><span> 镜音的小窝</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/artitalk/"><i class="fa-fw fas fa-commenting"></i><span> 说说</span></a></div><div class="menus_item"><a class="site-page" href="/comments/"><i class="fa-fw fas fa-comment"></i><span> 留言板</span></a></div><div class="menus_item"><a class="site-page" href="/4806bed7.html"><i class="fa-fw fas fa-user-circle"></i><span> 关于</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">论文研读：《A Lightweight Graph Transformer Network for Human Mesh Reconstruction from 2D Human Pose》</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2022-03-23T00:00:00.000Z" title="发表于 2022-03-23 00:00:00">2022-03-23</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2022-05-03T04:39:34.589Z" title="更新于 2022-05-03 04:39:34">2022-05-03</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E7%A6%81%E5%8C%BA/">禁区</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">2.9k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>9分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="论文研读：《A Lightweight Graph Transformer Network for Human Mesh Reconstruction from 2D Human Pose》"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><details class="folding-tag" blue=""><summary> 词汇表 </summary>
              <div class="content">
              <div class="table-container"><table><thead><tr><th style="text-align:center">英</th><th style="text-align:center">中</th></tr></thead><tbody><tr><td style="text-align:center">human pose estimation(HPE)</td><td style="text-align:center">人体姿态估计</td></tr><tr><td style="text-align:center">human body articulation</td><td style="text-align:center">人体关节</td></tr><tr><td style="text-align:center">depth ambiguity</td><td style="text-align:center">深度模糊</td></tr><tr><td style="text-align:center">occlusion</td><td style="text-align:center">遮挡问题</td></tr><tr><td style="text-align:center">end-to-end</td><td style="text-align:center">端到端的</td></tr><tr><td style="text-align:center">off-the-shelf</td><td style="text-align:center">现成的</td></tr><tr><td style="text-align:center">front end</td><td style="text-align:center">前端</td></tr><tr><td style="text-align:center">modular</td><td style="text-align:center">模块化的</td></tr><tr><td style="text-align:center">be incorporated with</td><td style="text-align:center">被并入</td></tr><tr><td style="text-align:center">Graph Transformer network for human mesh ReconStruction from 2D human pose(GTRS)</td><td style="text-align:center">从2D人体姿势中用图转换网络进行人体网格重构</td></tr><tr><td style="text-align:center">graph convolutional network(GCN)</td><td style="text-align:center">图卷积网络</td></tr><tr><td style="text-align:center">kinematics</td><td style="text-align:center">运动学</td></tr><tr><td style="text-align:center">global dependency</td><td style="text-align:center">全局依赖</td></tr><tr><td style="text-align:center">parallel graph transformer block</td><td style="text-align:center">并行图转化块</td></tr><tr><td style="text-align:center">3D coordinate</td><td style="text-align:center">3D坐标</td></tr><tr><td style="text-align:center">vertice</td><td style="text-align:center">顶点</td></tr><tr><td style="text-align:center">depth sensor</td><td style="text-align:center">深度传感器</td></tr><tr><td style="text-align:center">inertial measurement unit</td><td style="text-align:center">惯性测量单元</td></tr><tr><td style="text-align:center">vision transformer</td><td style="text-align:center">视觉转换器</td></tr><tr><td style="text-align:center">prior knowledge</td><td style="text-align:center">先验知识</td></tr><tr><td style="text-align:center">channel number</td><td style="text-align:center">通道数</td></tr><tr><td style="text-align:center">Multi-Head Self-Attention Layer(MHA)</td><td style="text-align:center">多头自监督层</td></tr><tr><td style="text-align:center">Miltilayer perceptron(MLP)</td><td style="text-align:center">多层感知机</td></tr><tr><td style="text-align:center">indeterminate</td><td style="text-align:center">模糊的</td></tr></tbody></table></div>
              </div>
            </details>
<h1 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h1><ul>
<li>现有的基于深度学习的人体网格重构方法为了更高的准确性往往会建构更大的网络，忽视了计算复杂度和模型大小。</li>
<li>本文提出的<code>GTRS</code>是一个轻量级的、基于姿势的方法，能2D人体姿势中重构人体网格。</li>
<li>文章提出了一个<code>姿势分析模块</code>，这个模块用<code>图转换器</code>来挖掘<emp>结构化的、隐含的</emp>关节联系。文章还提出了一个<code>网格回归模块</code>，这个模块将<code>网格模板</code>与提取出的姿势特征相结合，从而重建最终的人体网格。</li>
</ul>
<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><ul>
<li>今年来，HPE的研究进步已经超过了一个叫做<code>通过基本关键点结构预测2D或3D姿势</code>的方法。</li>
<li>很多人开始对从单张图中重构整个3D网格的研究感兴趣。</li>
<li><code>网格表示</code>能提供丰富的人体信息、可视化更好，游戏、人机交互、VR这类现实应用很欢迎网格表示。</li>
<li>由于<code>深度模糊</code>、<code>遮挡问题</code>、复杂的人体关节，从单张图片中进行HMR相当困难。</li>
<li>网格重构有两种方法<ol>
<li><code>基于图片的方法</code>，训练一个端到端的管道连接输入图像和输出网格。该方法表现良好，但是以计算复杂度和复杂模型为代价的。</li>
<li>采用现成的<code>2D姿势探测器</code>作为前端，用2D姿势作为输入设计网格重构模型。</li>
</ol>
</li>
<li>现实应用需要在资源受限的平台的同时具备高效率、可部署性。上述第二种方法在现实应用中有优点。</li>
<li><code>基于姿势的方法</code>提供了模块化的设计，这个设计能轻松并入任何现有的2D姿势探测器中。快速的姿势探测器能部署在移动设备并实时运行。</li>
<li><code>基于姿势的方法</code>的输入是探测到的2D姿势，数据稀疏，大小是J×2，其中J是关节数量。</li>
<li><code>GTRS</code>是一个<code>基于姿势的方法</code>。</li>
<li>GTRS包括：<code>姿势分析模块</code>、<code>网格回归模块</code>。</li>
<li>很多<code>图神经网络（GCN）</code>在3D HPE和网格重构工作中进展迅速，因为他们用了人体运动学的图结构。</li>
<li>GCN有强大的能力展示图结构数据，但不允许网络学习各种关系样式。举个例子。两个膝盖关节在人走路时有某种暗含的联系，但是在图表示中并不相连。转换器有强大能力通过<code>自监督机制</code>捕捉全局依赖，但是本地的连接信息不能高效地建模出来。</li>
<li>为全方位从2D姿势中探索人体运动学信息，作者提出了<code>并行图转化块</code>来对结构化的关系或非显性关系进行建模。然后用一个<code>网格回归模块</code>对<code>姿势特征</code>和<code>网格模板特征</code>建模，同时计算开销很小。GTRS最终输出是网格顶点的3D坐标。</li>
<li>作者总结了他们的主要贡献为：<ol>
<li>注意到了现在方法主要关注高精确度、忽视了计算和内存花销。GTRS作为<emp>轻量级的、基于姿势的</emp>方法，从<emp>2D姿势中</emp>进行人体网格重构。</li>
<li>作者提出拥有<emp>并行</emp>设计的<code>姿势分析模块</code>，能更好地对人体动力学信息进行利用。在该模块中，作者提出了<code>图转换块</code>，内有固定的、可学习的邻接矩阵来同时探索<emp>结构化的和隐式</emp>人体关节关系。</li>
<li>GTRS更少参数，更小计算开销，效果更好。</li>
</ol>
</li>
</ul>
<h1 id="Related-Work"><a href="#Related-Work" class="headerlink" title="Related Work"></a>Related Work</h1><h2 id="人体网格二重构"><a href="#人体网格二重构" class="headerlink" title="人体网格二重构"></a>人体网格二重构</h2><ul>
<li>从图片中进行HMR更高效、更方便，并没有要额外的设备（如<code>深度传感器</code>、<code>惯性测量单元</code>等）。</li>
<li>大量的先前研究都是用参数化的人体模型，训练一个网络来回归模型参数。</li>
</ul>
<h2 id="图卷积网络"><a href="#图卷积网络" class="headerlink" title="图卷积网络"></a>图卷积网络</h2><ul>
<li>由于GCN将人体关节作为图结构进行直观建模、能更好地捕捉人体运动学，<code>图卷积网络（GCN）</code>广泛被运用于<code>3D人体姿态估计（3D HPE）</code>。因此GCN在HMR领域备受关注。</li>
</ul>
<h2 id="视觉转换器"><a href="#视觉转换器" class="headerlink" title="视觉转换器"></a>视觉转换器</h2><ul>
<li><code>计算机视觉</code>领域内转换器架构发展迅速。转换器监督机制的全局表示能力在许多视觉工作（如物体检测、图像分类、分割、HPE等）中能力强大。</li>
<li>GTRS根据先验知识，利用GCN对特征进行建模，然后使用转换器来探索全局依赖。</li>
</ul>
<h1 id="方法论"><a href="#方法论" class="headerlink" title="方法论"></a>方法论</h1><ul>
<li><code>GTRS</code>是<code>基于姿势的</code>，这意味着GTRS里面没有<code>2D姿势探测器</code>。</li>
<li>GTRS的输入是由现成的2D姿势探测器得到的预估2D姿势，可表示为<script type="math/tex">X_{in} \in R^{J \times 2}</script>，其中J是关节数量。</li>
<li>一个<code>特征嵌入层</code>通过一个高特征维度D，将输入<script type="math/tex">X_{in} \in R^{J \times 2}</script>嵌入到<script type="math/tex">X_{pose} \in R^{J \times D}</script>。然后，<code>姿势分析模块</code>返回建模特征<script type="math/tex">X_{pose}^{'}\in R^{J \times D}</script>。然后，将网格模板<script type="math/tex">M_{temp}\in R^{6890 \times 3}</script>嵌入到<code>网格模板特征</code><script type="math/tex">X_{temp}\in R^{T\times D}</script>，其中T是通道数。然后，把<script type="math/tex">X^{'}_{pose}</script>和<script type="math/tex">X_{temp}</script>喂给<code>网格回归模块</code>，输出是<script type="math/tex">X_{out}\in R^{(J+T)\times D}</script>。最后，预估的网格参数<script type="math/tex">Y\in R^{6890\times 3}</script>在回归头（regression head）后能得到。</li>
</ul>
<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><h3 id="GCN"><a href="#GCN" class="headerlink" title="GCN"></a>GCN</h3><ul>
<li>用GCN来对2D图像特征进行建模，<script type="math/tex">X\in R^{J\times D}</script>，其中J是关节数、D是输入特征的维度。给定一个基于关节连通性的邻接矩阵<script type="math/tex">A\in R^{J\times J}</script>，一个GCN层的输出<script type="math/tex">X^{'}\in R^{J\times D^{'}}</script>可表示为  <script type="math/tex; mode=display">X^{'}=\sigma(AXW)</script>其中<script type="math/tex">\sigma(·)</script>是非线性网络的激活函数，<script type="math/tex">W\in R^{D\times D^{'}}</script>是可学习的权重矩阵，这个矩阵改变了特征维度（从<script type="math/tex">D</script>到<script type="math/tex">D^{'}</script>）。激活函数在这里采用的是GELU。</li>
</ul>
<h3 id="转换器"><a href="#转换器" class="headerlink" title="转换器"></a>转换器</h3><ul>
<li>转换器块中核心功能是<code>多头自监督层（MHA）</code>。</li>
<li>输入<script type="math/tex">X\in R^{J\times D}</script>先通过三个线性变换映射成三个矩阵：查询矩阵Q、关键字矩阵K、值矩阵V。  <script type="math/tex; mode=display">Q=XW_Q,K=XW_K,V=XW_V</script>其中<script type="math/tex">W_Q,W_K,W_V\in R^{D\times D}</script>。</li>
<li>被scaled后的点积注意力机制表示为如下映射函数：  <script type="math/tex; mode=display">Attention(Q,K,V)=Softmax(QK^T/\sqrt d)V</script>其中<script type="math/tex">1/\sqrt d</script>是一个用来正则化的比例系数，防止斜率太小。</li>
<li>接下来MHA从不同的表示子空间的不同方向中，用多头来对信息进行连带建模。每个头都用了scaled的并行的点积注意机制。</li>
<li>MSA的输出是一连串的h个注意力头的输出。  <script type="math/tex; mode=display">MSA(Q,K,V)=Concat(H_1,H_2,···,H_h)W_{out}</script>其中<script type="math/tex">H_i=Attention(Q_i,K_i,V_i),i\in [1,···,h]</script></li>
</ul>
<h2 id="姿势分析模块"><a href="#姿势分析模块" class="headerlink" title="姿势分析模块"></a>姿势分析模块</h2><ul>
<li>在姿势分析模块中，用小型D维嵌入转换器，这样能比较轻量级，但表示能力还不太够，所以再引入<code>网格模板</code>，这样回归效果更好。</li>
<li>鉴于姿势特征和网格模板特征的规模不同，设计了双分支架构，用了两个转换器，先对两个特征进行建模，然后用一个融合转换器将信息融合起来。输出<script type="math/tex">X_{fusion} \in R^{(J+T)\times D}</script>，该矩阵能被分为<script type="math/tex">X_{B_{pose}}\in R^{J\times D}</script>和<script type="math/tex">X_{B_{temp}}\in R^{T\times D}</script>。这两个矩阵再作为输入进入下一阶段。</li>
<li>最后，一个回归头（这个回归头是一个<code>多层感知机</code>）对<script type="math/tex">X_{out}\in R^{(J+T)\times D}</script>进行上采样，产生最终输出。</li>
</ul>
<h2 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h2><ul>
<li>测量了预估的不确定3D姿势矩阵<script type="math/tex">J_{3D\_int}\in R^{K \times 3}</script>和实际的3D姿势矩阵<script type="math/tex">\hat{J}_{3D}\in R^{K \times 3}</script>之间的L1范数。其中K是关节数。<br>-损失函数如下：<script type="math/tex; mode=display">L_{J\_int}=\frac{1}{K}\sum\limits_{i=1}^{K}||J_{3D\_int}-\hat{J}_3D||_1</script></li>
<li>在预训练姿势分析模块后，我们训练姿势分析模块和网格恢复模块。用到了以下损失函数。</li>
<li>网格节点损失：预估3D网格节点坐标<script type="math/tex">V_{3D}\in R^{M\times 3}</script>和实际3D网格节点坐标<script type="math/tex">\hat{V}_{3D}\in R^{M\times 3}</script>之间的L1范数。其中M是节点数。网格节点损失定义为：<script type="math/tex">L_{Vertex}=\frac{1}{M}\sum\limits_{i=1}^{M}||V_{3D}-\hat{V}_{3D}||_1</script></li>
<li>3D关节坐标损失：预测3D网格坐标后就要根据关节回归矩阵<script type="math/tex">V_{3D}\in R^{K\times M}</script>，根据预测的网格来计算3D姿势。损失用通过预测网格RV得到的回归3D姿势和实际3D姿势<script type="math/tex">\hat{J}_{3D}\in R^{K\times 3}</script>之间的L1范数表示。损失函数为：<script type="math/tex">L_{Joint}=\frac{1}{K}\sum\limits_{i=1}^{K}||RV-\hat{J}_{3D}||_1</script></li>
<li>根据上述四个损失得到总损失：<script type="math/tex">L=\lambda_v L_{Vertex}+\lambda_j L_{Joint}+\lambda_n L_{Normal}+\lambda_e L_{Edge}</script>。其中<script type="math/tex">\lambda_v=1,\lambda_j=0.01,\lambda_n=0.01,\lambda_e=0.01</script>。</li>
</ul>
<h1 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h1><h2 id="消融学习"><a href="#消融学习" class="headerlink" title="消融学习"></a>消融学习</h2><ul>
<li>在Human3.6M数据集上做了消融研究。研究了图转换块在姿势分析模块中的作用。不用GCN只用转换块的话，MPJPE和PA-MPJPE效果大大降低，说明GCN的强连通性很重要。如果让6个图转换块可学习的话，效果更好。如果不用1个图转换块，其他5个图转换块可学习，这样效果最好，因为结构化的和蕴含的人体特征都能被捕获。</li>
<li>加入模板网格可以帮助对网格更好回归。</li>
<li>用更精确的2D姿势输入能增强GTRS的精确性。用一个轻量级的2D姿势探测器可以在保证精确度的前提下让计算和内存开销小。</li>
<li>GTRS在处理野生问题时鲁棒性更好。</li>
<li>就算在拥挤复杂的场景下，GTRS能重建可接受的人体网格。</li>
</ul>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>通过运用<code>平行图转换块</code>，姿势分析模块用来挖掘结构化的和隐性的关节联系。然后用网格回归模块，通过提取出的姿势特征和网格模板，有效地重建最终的人体网格。</p>
<ul>
<li>作为基于姿势的方法，GTRS没办法仅通过2D姿势作为输入就能恢复多样的人体形态。基于图像的方法通常更精确，但基于姿势的方法更轻量级，也有研究价值。</li>
<li>未来我们想在保持轻量级的同时改善重建模能力，我们会尝试加入另一个分支，从图像中提取人体姿势特征。</li>
</ul>
</article><div class="post-copyright"><div class="post-copyright__title"><span class="post-copyright-info"><h>论文研读：《A Lightweight Graph Transformer Network for Human Mesh Reconstruction from 2D Human Pose》</h></span></div><div class="post-copyright__type"><span class="post-copyright-info"><a href="http://roundedorange.top/db37c32a.html">http://roundedorange.top/db37c32a.html</a></span></div><div class="post-copyright-m"><div class="post-copyright-m-info"><div class="post-copyright-a" style="display: inline-block;width: 120px"><h>作者</h><div class="post-copyright-cc-info"><h>滚圆的小橘子</h></div></div><div class="post-copyright-c" style="display: inline-block;width: 120px"><h>发布于</h><div class="post-copyright-cc-info"><h>2022-03-23</h></div></div><div class="post-copyright-u" style="display: inline-block;width: 120px"><h>更新于</h><div class="post-copyright-cc-info"><h>2022-05-03</h></div></div><div class="post-copyright-c" style="display: inline-block;width: 120px"><h>许可协议</h><div class="post-copyright-cc-info"><a class="icon" rel="noopener" target="_blank" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a><a rel="noopener" target="_blank" title="CC BY 4.0" href="https://creativecommons.org/licenses/by/4.0/deed.zh">CC BY 4.0</a></div></div></div></div></div><div class="tag_share"><div class="post_share"><div class="social-share" data-image="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js" defer></script></div></div><link rel="stylesheet" href="/css/coin.css" media="defer" onload="this.media='all'"/><div class="post-reward"><button class="tip-button reward-button"><span class="tip-button__text">打赏给小橘子</span><div class="coin-wrapper"><div class="coin"><div class="coin__middle"></div><div class="coin__back"></div><div class="coin__front"></div></div></div><div class="reward-main"><ul class="reward-all"><li class="reward-item"><a href="/pictures/alipay.jpg" target="_blank"><img class="post-qr-code-img" src="/pictures/alipay.jpg" alt="支付宝"/></a><div class="post-qr-code-desc">支付宝</div></li></ul></div></button></div><audio id="coinAudio" src="https://npm.elemecdn.com/akilar-candyassets@1.0.16/audio/coin.mp3"></audio><script defer="defer" src="/js/coin.js"></script><hr/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div id="twikoo-wrap"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Abstract"><span class="toc-number">1.</span> <span class="toc-text">Abstract</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Introduction"><span class="toc-number">2.</span> <span class="toc-text">Introduction</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Related-Work"><span class="toc-number">3.</span> <span class="toc-text">Related Work</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BA%BA%E4%BD%93%E7%BD%91%E6%A0%BC%E4%BA%8C%E9%87%8D%E6%9E%84"><span class="toc-number">3.1.</span> <span class="toc-text">人体网格二重构</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9B%BE%E5%8D%B7%E7%A7%AF%E7%BD%91%E7%BB%9C"><span class="toc-number">3.2.</span> <span class="toc-text">图卷积网络</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%A7%86%E8%A7%89%E8%BD%AC%E6%8D%A2%E5%99%A8"><span class="toc-number">3.3.</span> <span class="toc-text">视觉转换器</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%96%B9%E6%B3%95%E8%AE%BA"><span class="toc-number">4.</span> <span class="toc-text">方法论</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%89%8D%E8%A8%80"><span class="toc-number">4.1.</span> <span class="toc-text">前言</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#GCN"><span class="toc-number">4.1.1.</span> <span class="toc-text">GCN</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%BD%AC%E6%8D%A2%E5%99%A8"><span class="toc-number">4.1.2.</span> <span class="toc-text">转换器</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%A7%BF%E5%8A%BF%E5%88%86%E6%9E%90%E6%A8%A1%E5%9D%97"><span class="toc-number">4.2.</span> <span class="toc-text">姿势分析模块</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0"><span class="toc-number">4.3.</span> <span class="toc-text">损失函数</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%AE%9E%E9%AA%8C"><span class="toc-number">5.</span> <span class="toc-text">实验</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%B6%88%E8%9E%8D%E5%AD%A6%E4%B9%A0"><span class="toc-number">5.1.</span> <span class="toc-text">消融学习</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%80%BB%E7%BB%93"><span class="toc-number">6.</span> <span class="toc-text">总结</span></a></li></ol></div></div></div></div></main><footer id="footer" style="background-image: url('https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg')"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2022 By 滚圆的小橘子</div><div class="footer_custom_text"><a href="https://icp.gov.moe/?keyword=20228421" target="_blank">萌ICP备20228421号</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="font-plus" type="button" title="放大字体"><i class="fas fa-plus"></i></button><button id="font-minus" type="button" title="缩小字体"><i class="fas fa-minus"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="chat_btn" type="button" title="rightside.chat_btn"><i class="fas fa-sms"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><div class="search-dialog__title" id="local-search-title">本地搜索</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div></div><hr/><div id="local-search-results"></div><span class="search-close-button"><i class="fas fa-times"></i></span></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.js"></script><script src="/js/search/local-search.js"></script><script>var preloader = {
  endLoading: () => {
    document.body.style.overflow = 'auto';
    document.getElementById('loading-box').classList.add("loaded")
  },
  initLoading: () => {
    document.body.style.overflow = '';
    document.getElementById('loading-box').classList.remove("loaded")

  }
}
window.addEventListener('load',preloader.endLoading())</script><div class="js-pjax"><script>if (!window.MathJax) {
  window.MathJax = {
    tex: {
      inlineMath: [ ['$','$'], ["\\(","\\)"]],
      tags: 'ams'
    },
    chtml: {
      scale: 1.2
    },
    options: {
      renderActions: {
        findScript: [10, doc => {
          for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
            const display = !!node.type.match(/; *mode=display/)
            const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
            const text = document.createTextNode('')
            node.parentNode.replaceChild(text, node)
            math.start = {node: text, delim: '', n: 0}
            math.end = {node: text, delim: '', n: 0}
            doc.math.push(math)
          }
        }, ''],
        insertScript: [200, () => {
          document.querySelectorAll('mjx-container:not\([display]\)').forEach(node => {
            const target = node.parentNode
            if (target.nodeName.toLowerCase() === 'li') {
              target.parentNode.classList.add('has-jax')
            } else {
              target.classList.add('has-jax')
            }
          });
        }, '', false]
      }
    }
  }
  
  const script = document.createElement('script')
  script.src = 'https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js'
  script.id = 'MathJax-script'
  script.async = true
  document.head.appendChild(script)
} else {
  MathJax.startup.document.state(0)
  MathJax.texReset()
  MathJax.typeset()
}</script><script>(()=>{
  const $countDom = document.getElementById('twikoo-count')
  const init = () => {
    twikoo.init(Object.assign({
      el: '#twikoo-wrap',
      envId: 'environment-8gzfnzxyeedc08e9',
      region: ''
    }, null))
  }

  const getCount = () => {
    twikoo.getCommentsCount({
      envId: 'environment-8gzfnzxyeedc08e9',
      region: '',
      urls: [window.location.pathname],
      includeReply: false
    }).then(function (res) {
      $countDom.innerText = res[0].count
    }).catch(function (err) {
      console.error(err);
    });
  }

  const loadTwikoo = (bool = false) => {
    if (typeof twikoo === 'object') {
      init()
      bool && $countDom && setTimeout(getCount,0)
    } else {
      getScript('https://cdn.jsdelivr.net/npm/twikoo/dist/twikoo.all.min.js').then(()=> {
        init()
        bool && $countDom && setTimeout(getCount,0)
      })
    }
  }

  if ('Twikoo' === 'Twikoo' || !true) {
    if (true) btf.loadComment(document.getElementById('twikoo-wrap'), loadTwikoo)
    else loadTwikoo(true)
  } else {
    window.loadOtherComment = () => {
      loadTwikoo()
    }
  }
})()</script></div><script defer data-pjax src="/js/kernel.js"></script><script defer data-pjax src="/js/tongji.js"></script><canvas class="fireworks" mobile="false"></canvas><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/fireworks.min.js"></script><script src="//code.tidio.co/nwdy4oqyxwgfsh9wggjjluoe8qtkpdxp.js" async="async"></script><script>function onTidioChatApiReady() {
  window.tidioChatApi.hide();
  window.tidioChatApi.on("close", function() {
    window.tidioChatApi.hide();
  });
}
if (window.tidioChatApi) {
  window.tidioChatApi.on("ready", onTidioChatApiReady);
} else {
  document.addEventListener("tidioChat-ready", onTidioChatApiReady);
}

var chatBtnFn = () => {
  document.getElementById("chat_btn").addEventListener("click", function(){
    window.tidioChatApi.show();
    window.tidioChatApi.open();
  });
}
chatBtnFn()
</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.js"></script><script src="https://cdn.jsdelivr.net/gh/metowolf/MetingJS@1.2/dist/Meting.min.js"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><!-- hexo injector body_end start --><script data-pjax>
  function butterfly_swiper_injector_config(){
    var parent_div_git = document.getElementById('recent-posts');
    var item_html = '<div class="recent-post-item" style="height: auto;width: 100%"><div class="blog-slider swiper-container-fade swiper-container-horizontal" id="swiper_container"><div class="blog-slider__wrp swiper-wrapper" style="transition-duration: 0ms;"><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="fc8dd9e7.html" alt=""><img width="48" height="48" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2022-01-14</span><a class="blog-slider__title" href="fc8dd9e7.html" alt="">小橘子的butterfly魔改记录</a><div class="blog-slider__text">魔改一时爽，升级火葬场。</div><a class="blog-slider__button" href="fc8dd9e7.html" alt="">详情   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="88b34f83.html" alt=""><img width="48" height="48" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2022-04-16</span><a class="blog-slider__title" href="88b34f83.html" alt="">术力口第一精神病院对病人滚圆的小橘子的异常行为记录</a><div class="blog-slider__text">再怎么看我也不知道怎么描述它的啦！</div><a class="blog-slider__button" href="88b34f83.html" alt="">详情   </a></div></div></div><div class="blog-slider__pagination swiper-pagination-clickable swiper-pagination-bullets"></div></div></div>';
    console.log('已挂载butterfly_swiper')
    parent_div_git.insertAdjacentHTML("afterbegin",item_html)
    }
  var elist = 'undefined'.split(',');
  var cpage = location.pathname;
  var epage = '/';
  var flag = 0;

  for (var i=0;i<elist.length;i++){
    if (cpage.includes(elist[i])){
      flag++;
    }
  }

  if ((epage ==='all')&&(flag == 0)){
    butterfly_swiper_injector_config();
  }
  else if (epage === cpage){
    butterfly_swiper_injector_config();
  }
  </script><script defer src="https://unpkg.zhimg.com/hexo-butterfly-swiper/lib/swiper.min.js"></script><script defer data-pjax src="https://unpkg.zhimg.com/hexo-butterfly-swiper/lib/swiper_init.js"></script><script data-pjax src="https://npm.elemecdn.com/hexo-filter-gitcalendar/lib/gitcalendar.js"></script><script data-pjax>
  function gitcalendar_injector_config(){
      var parent_div_git = document.getElementById('recent-posts');
      var item_html = '<div class="recent-post-item" style="width:100%;height:auto;padding:10px;"><style>#git_container{min-height: 280px}@media screen and (max-width:650px) {#git_container{min-height: 0px}}</style><div id="git_loading" style="width:10%;height:100%;margin:0 auto;display: block;"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 50 50" style="enable-background:new 0 0 50 50" xml:space="preserve"><path fill="#d0d0d0" d="M25.251,6.461c-10.318,0-18.683,8.365-18.683,18.683h4.068c0-8.071,6.543-14.615,14.615-14.615V6.461z" transform="rotate(275.098 25 25)"><animatetransform attributeType="xml" attributeName="transform" type="rotate" from="0 25 25" to="360 25 25" dur="0.6s" repeatCount="indefinite"></animatetransform></path></svg><style>#git_container{display: none;}</style></div><div id="git_container"></div></div>';
      parent_div_git.insertAdjacentHTML("afterbegin",item_html)
      console.log('已挂载gitcalendar')
      }

    if( document.getElementById('recent-posts') && (location.pathname ==='/'|| '/' ==='all')){
        gitcalendar_injector_config()
        GitCalendarInit("https://gitcalendar.akilar.top/api?RoundedOrange",['#e4dfd7', '#f9f4dc', '#f7e8aa', '#f7e8aa', '#f8df72', '#fcd217', '#fcc515', '#f28e16', '#fb8b05', '#d85916', '#f43e06'],'RoundedOrange')
    }
  </script><script async src="//at.alicdn.com/t/font_2032782_8d5kxvn09md.js"></script><!-- hexo injector body_end end --></body></html>